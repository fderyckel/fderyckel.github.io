---
title: "Kmeans with regime changes"
author: "Francois de Ryckel"
date: '2022-10-12'
categories: [kmeans, code, analysis, tidymodel]
editor: source
date-modified: '2022-10-12'
---

This post is about how to use Kmeans to classify various market regimes or to use Kmeans to classify financial observations. 

::: {.callout-tip appearance="simple"} 

# Market regime 

Financial markets have the tendency to change their behavior over time, which can create regimes, or periods of fairly persistent market conditions. Investors often look to discern the current market regime, looking out for any changes to it and how those might affect the individual components of their portfolioâ€™s asset allocation. Modeling various market regimes can be an effective tool, as it can enable macro-economically aware investment decision-making and better management of tail risks. 

:::

With K-means we are trying to establish groups of data that are **homegenous** and **distinctly different** from other groups.  The *K-* stands for the number of clusters we will create.  

The concept of distance comes in when deciding if a data point belongs to a cluster. The most common way to measure distance is the **Euclidean Distance**.  

With multivariate data set, it is important to normalize the data.  
A usual rule of thumb is to set the number of clusters as the square root of the number of observation. 

# Using R 

## Load up packages and read data 

```{r}
#| label: setting_up
#| warning: false
#| message: false
library(readr)        # load and read .csv file
library(glue)         # concatenate strings together
library(dplyr)        # the tidy plyr tool for data wrangling
library(tidyr)        # to use the drop_na function
the_path <- here::here()
df <- read_csv(glue(the_path, "/raw_data/AMD.csv")) |> 
  rename(date = Date, high = High, low = Low, close = Close, adj_close = 'Adj Close') |> 
  select(date, high, low, close, adj_close)
glimpse(df)
```

## Feature engineering 

```{r}
#| label: features_engineering_in_r
#| warning: false
#| message: false
library(TTR)      # The technical analysis package
yo <- aroon(df[, c('high', 'low')], n = 23)
df$aroon <- yo[, 3]
yo <- CCI(df[, c('high', 'low', 'close')], n = 17)
df$cci <- yo
yo <- chaikinVolatility(df[, c('high', 'low')], n = 13)
df$chaikinVol <- yo
df1 <- df |> 
  select(date, aroon, cci, chaikinVol, adj_close) |> 
  mutate(across(c(aroon, cci, chaikinVol), ~ as.numeric(scale(.)))) |>
  drop_na()
skimr::skim(df1 %>% select(-date))
# also good to check for correlation between variables. 
library(corrr)
df1 |> select(-date, -adj_close) |> 
  correlate() |> 
  rearrange() |> 
  shave()
```

These 3 variables seem to complete each other well as little to-no correlation. 

## Create clusters

```{r}
#| label: creating_cluster_in_r
library(purrr)     #use the map function
library(broom)     #use the glance function on kmeans 
df1sc <- df1 %>% select(-date, -adj_close)
kclusts <- tibble(k = 1:9) |> 
  mutate(kclust = map(k, ~kmeans(df1sc, centers = .x, nstart = 30, iter.max = 50L)), 
         glanced = map(kclust, glance), 
         augmented = map(kclust, augment, df1))
kclusts |> unnest(cols = c('glanced'))
```

There are several ways to choose the ideal number of clusters.  One of them is the elbow method, another one is the Silhouette Method. 

The **tot.withinss** is the total within-cluster sum of square. This is the value used for the eblow method. 

For the Silhouette Method, we can use the **cluster** package. 

```{r}
#| label: calculate_silhoutte_value_in_r
#| cache: true
avg_sil <- function(k) { 
  kmeans_object <- kmeans(df1sc, centers = k, iter.max = 50L)
  silh = cluster::silhouette(kmeans_object$cluster, dist(df1sc))
  mean(silh[, 3])
  }
# Compute and plot wss for k = 2 to k = 15
yo <- tibble(k_values =  2:9) |> 
  mutate(avg_sil_values = map_dbl(k_values, avg_sil))
yo
```

A more elegant way to do that, using [this post from SO](https://stackoverflow.com/questions/63780363/r-using-purrr-map-function-to-calculate-silhouette-distances-of-kmeans-model)
```{r}
#| label: calculate_silhoutte_value_in_r_elegant
#| cache: true
yo <- kclusts |> 
  mutate(silhouetted = map(augmented, ~ cluster::silhouette(as.numeric(levels(.x$.cluster))[.x$.cluster], dist(df1sc)))) |> 
  select(k, silhouetted) |> unnest(cols=c('silhouetted')) |> 
  group_by(k) %>% 
  summarise(avg_sil_values = mean(silhouetted[,3]))
yo
```



## Some visualizations 

### Elbow method 

```{r}
#| label: vizualise_kmeans_elbow
#| fig-cap: "Total within-cluster sum of square for k-cluster"
library(ggplot2)
kclusts |> 
  unnest(cols = c('glanced')) |> 
  ggplot(aes(k, tot.withinss)) + 
  geom_line(alpha = 0.5, size = 1.2, color = 'midnightblue') + 
  geom_point(size = 2, color = 'midnightblue')
  
```
Based on the elbow method, I would be tempted to choose to 5 clusters (2 seems another obvious one).  

### Silhouette Method 

```{r}
#| label: silhouette_score_graph_r
#| fig-cap: "Silhouette score for k-clusters"
yo |> ggplot(aes(k, avg_sil_values)) + 
  geom_line(alpha = 0.5, size = 1.2, color = 'midnightblue') + 
  geom_point(size = 2, color = 'midnightblue')
  
```
2 is the winner ;-) 

### Plotting the stocks with clustered observations 

```{r}
#| label: plotting_with_2clusters_observation
#| warning: false
#| message: false
#| fig-cap: "Plotting adjusted close price with only 2 clusters"
library(lubridate)
yo <- kmeans(df1 |> select(-date, -adj_close), centers = 2)
augment(yo, df1) |> filter(date >= today() - 500) |> 
  ggplot(aes(x = date, y = adj_close)) + 
    geom_line(alpha = 0.5, color = 'midnightblue') + 
    geom_point(aes(color = .cluster)) + 
    theme(legend.position = 'none')
```

```{r}
#| fig-cap: "Plotting adjusted close price with only 3 clusters"
#| label: plotting_with_only_3clusters
yo <- kmeans(df1 |> select(-date, -adj_close), centers = 3)
augment(yo, df1) |> filter(date >= today() - 500) |> 
  ggplot(aes(x = date, y = adj_close)) + 
    geom_line(alpha = 0.5, color = 'midnightblue') + 
    geom_point(aes(color = .cluster)) + 
    theme(legend.position = 'none')
```

```{r}
#| label: platting_with_only_6clusters
#| fig-cap: "Plotting adjusted close price with only 6 clusters"
yo <- kmeans(df1 |> select(-date, -adj_close), centers = 6)
augment(yo, df1) |> filter(date >= today() - 500) |> 
  ggplot(aes(x = date, y = adj_close)) + 
    geom_line(alpha = 0.5, color = 'midnightblue') + 
    geom_point(aes(color = .cluster)) + 
    theme(legend.position = 'none')
```


# Using python 
Original blog post 

```{python}
#| label: get_and_save_the_data
#| eval: false

import yfinance as yf     #only to download data
data  = yf.download("AMD")
data.to_csv("../../raw_data/AMD.csv")
```


```{python}
#| label: load_and_transform_data
#| eval: false

import pandas as pd
py_df = pd.read_csv("../../raw_data/intc.csv", names = ['date', 'open', 'high', 'low', 'close', 'adj_close', 'volume']).iloc[1: , :]
py_df.tail()
py_df.info()
py_df.shape
py_df_melt = py_df.melt(id_vars = 'date', value_vars = ['open', 'high', 'low', 'close'], value_name = 'prices', var_name = 'price_point')
py_df_melt.info()
py_df_melt.shape
```


Let's graph the last year of data 

```{python}
#| label: graph_stocks_using_pyplot
#| warning: false
#| message: false
#| eval: false

import matplotlib.pyplot as plt
ta_df2 = ta_df.tail(250).copy()
ta_df2['adj_close'] = py_df['adj_close']
ta_df2['date_time'] = pd.to_datetime(ta_df2['date_time'], utc=True)
ta_df2['adj_close'] = pd.to_numeric(ta_df2['adj_close'])
fig = plt.figure(figsize = (12, 8)) 
gs = fig.add_gridspec(3, hspace=0)
axs = gs.subplots(sharex=True)
#plt.figure(figsize = (12, 8))
axs[0].plot(ta_df2['date_time'], ta_df2['adj_close'])
axs[0].set_ylim(25, 55)
#axs[0].set_title('INTC price')
axs[1].plot(ta_df2['date_time'], ta_df2['aaron'],  'tab:green')
axs[1].set_ylim(-105, 105)
#axs[1].set_title('Aaron ind.')
axs[2].plot(ta_df2['date_time'], ta_df2['ht'], 'tab:red')
axs[2].set_ylim(-50,320)
for ax in axs:
    ax.label_outer()
    
plt.show()
```


```{python}
#| label: model_cluster_in_python
#| eval: false
#| cache: true
from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans
inertia = []
sil_score = []
ta_df.pop('date_time')
for n_clusters in range(2, 14): 
  kmeans = KMeans(n_clusters = n_clusters, random_state=0)
  preds = kmeans.fit_predict(ta_df)
  inertia.append(kmeans.inertia_ / n_clusters)
  sil_score.append(silhouette_score(ta_df, preds))
  
inertias = pd.DataFrame({n_clusters: range(2, 14), "inertia": inertia})
sil_scores = pd.DataFrame({n_clusters: range(2, 14), "sil_score": sil_score})
print(inertias)
print(sil_scores)
```