---
title: "AutoCorrelation, Stationarity and Random-Walk - Part 1"
author: "Francois de Ryckel"
date: '2022-09-29'
description: 'A dive into the concepts of autocorrelation and stationarity of time-series.  We also get into how to plot correlogram using R and Python, random-walk, white-noise. Finally, we check how to compose and decompose time-series into their various components (trend, seasonanilty)'
categories: [time-series]
date-modified: '2022-09-09'
---

This post is to set up the basic concepts of time-series analysis.  

# Autocovariance & autocorrelation 

Autocorrelation as the name indicates is the correlation of the time-series with itself, more specifically with a lag version of itself. 

Let's consider $\{X_t\}$ a time series.  

*   Then the mean function of $\{X_t\}$ (the first moment) is defined as $\mu_t = \textbf{E}(X_t)$.  In other words, $\mu_t$ is the expected value of the time series at point t.  
*   The Variance of the time series is defined as $\sigma_t ^2 = Var(X_t) = \textbf{E}[(X_t - \mu_t)^2]$. 
*   In general, $\mu_t$ and $\sigma_t ^2$ are different at different point in time. 

Now, we define the **autocovariance** function of the time series as $$\gamma(s, t) = Cov(X_s, X_t) = \textbf{E}[(X_s - \mu_s)(X_t - \mu_t)]$$. 
In the same vein, we define the **autocorrelation** function of the time series as 
$$\rho(s,t) = Corr(X_s, X_t) = \frac {\gamma (s, t)}{\sigma_s \sigma_t} = \frac{Cov(X_s, X_t)}{\sqrt{Var(X_s) Var(X_t)}}$$

Autocovariance and autocorrelation measure the linear correlation between between two points $X_s$ and $X_t$ on the same time-series. 

Few properties of autocavariance and autocorrelation of time-series 

* $\gamma(t, t) = \sigma_t^2$ 
* $\gamma(s, t) = \gamma(t, s)$ 
* $|\gamma(s, t)| \le \sigma_s \sigma_t$ 
* $\rho(t, t) \equiv 1$

## Autocorrelation plots - Correlogram 

As exercise, we can plot the auto-correlation of a non-stationary (aka with significant autocorrelation) time-series.  We are using the [Monthly Milk production](https://www.kaggle.com/datasets/bhaveshsonagra/monthly-milk-production) (no idea where the data come from)

### Using R 

In R the standard function to plot a correlogram is the *acf()* function

```{r}
#| warning: false
#| message: false

library(readr)

milk <- read_csv('../../../raw_data/milk.csv')
acf(milk$milk_prod_per_cow_kg)
```

Graph clearly shows some seasonality (at the 12 lags ==> yearly correlation) which indicates that our data are non-stationary (next section). 

If we are more attached to the auto-correlation values, we can store the results in a dataframe. 

```{r}
yo <- acf(milk$milk_prod_per_cow_kg, plot = F)
yo
```


We could use the *ggplot* package to create a function to draw acf and get more customization.  We will re-use this function later as well. 

```{r}
# slightly fancier version (with more customization)
ggacf <- function(series) {
  significance_level <- qnorm((1 + 0.95)/2)/sqrt(sum(!is.na(series)))  
  a <- acf(series, plot=F)
  a.2 <- with(a, data.frame(lag, acf))
  g <- ggplot(a.2[-1,], aes(x=lag,y=acf)) + 
    geom_segment(mapping = aes(xend = lag, yend = 0), linewidth = 0.8) + 
    xlab('Lag') + ylab('ACF') + 
    geom_hline(yintercept=c(significance_level,-significance_level), linetype= 'dashed', color = 'dodgerblue4');

  # fix scale for integer lags
  if (all(a.2$lag%%1 == 0)) {
    g<- g + scale_x_discrete(limits = factor(seq(1, max(a.2$lag))));
  }
  return(g);
}
```


```{r}
library(ggplot2)
library(tibble)

ggacf(milk$milk_prod_per_cow_kg)
```

### Using Python 

In python, we need to use the *statsmodel* package. 

```{python}
from pandas import read_csv
import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_acf

df = read_csv('../../../raw_data/milk.csv', index_col=0)
plot_acf(df)
plt.show()
```


# Stationarity 

A time-series $\{X_t\}$ is (weakly) stationary if: 

* $E[X_t] = \mu$ is a constant 
* $E[X_t^2] < \infty$ 
* $Cov(X_t, X_{t+k}) = \gamma(k)$ is independent of t for each integer k. $\gamma(k)$ is called the lag $k$ autocovariance of function of $\{X_t\}$

# Random Walk & White Noise 

White noise is a special type of time-series and a special case of stationarity. The concept emerge when studying **Random Walk**.  $\{X_t\}$ is a random-walk if it satisfies the equation: 

$$X_t = X_{t-1} + W_t$$ {#eq-rw1}
where $\{W_t\}$ is a white-noise.  In other words, $W_t \sim iid N(0, \sigma_w^2)$



$\{W_t\}$ is a white-noise if 

* $E[W_t] = \mu$ is a constant for all t
* $Var[W_t] = \sigma_w^2$ is a constant 
* $Cov(W_s, W_t) = 0$ for any s and t with $s<t$.  In other words, any 2 subset of W are uncorrelated. 

If $\{W_t\}$ is iid (independent and identically distributed) and $\rho(k) = 1$ (when k=0) and $\rho(k) = 0$ (otherwise, aka for any other values of k), then $\{W_t\}$ is a white noise. 

Therefore, as $n \rightarrow \infty$, we can say that $\frac{1}{n} (X_1 + \dots + X_n) = E[X_t] = \mu$

A random walk is mean stationary: $E(X_t) = E(X_0)$.  However, the random walk is NOT variance stationary: $Var(X_t) = Var(X_{t-1}) + \sigma_w^2 \gt Var(X_{t-1})$.  

We can generate white-noise in R using the arima.sim() function.  

```{r}
set.seed(1234)

# Generate a white noise in R
wn <- stats::arima.sim(model = list(order = c(0, 0, 0)), n = 250)
df <- tibble(x = 1:250, y = as.vector(wn))

ggplot(df, aes(x, y)) + 
  geom_line(color = 'dodgerblue3') + 
  xlab('Time') + ylab('White Noise') + 
  labs(title = 'Generated White Noise')
```

And let's check the autocorrelation plot to visually confirm that. 

```{r}
# using the standard R function. 
acf(wn, lag.max = 20)
```

We could also use a ggplot function to plot the auto-correlation of our time-series. 

```{r}
ggacf(wn)
```

## Statistical test to check white-noise. 

In R we can use the Ljung-Box test (Portmanteau 'Q' test).  

```{r}
Box.test(wn, type = 'Ljung-Box', lag = 1)
```


# PACF 

The Partial Autocorrelation measures the correlation between $\{X_{t-k} \}$ and $\{ X_t \}$. 

```{r}
pacf(milk$milk_prod_per_cow_kg)
```




# Application to a financial asset 

We know that most financial assets prices are not stationary.  Let's take *SBUX* for instance. 
That being said, the log difference of their prices is stationary.  Note how $log(P_t) - log(P{t-1}) = log( \frac{P_t}{P_{t-1} )$

## Using R

```{r}
#| warning: false
#| message: false

library(dplyr)
library(lubridate)

df <- read_csv('../../../raw_data/SBUX.csv') |> arrange(date) |> 
  select(date, adjClose) |> 
  mutate(ret_1d = log(adjClose / lag(adjClose)), 
         ret_5d = log(adjClose / lag(adjClose, n = 5)), 
         y_t = log(adjClose) - log(lag(adjClose)), 
         day_of_week = weekdays(date)) |> 
  filter(date > '2018-01-01' & day_of_week == 'Tuesday')

ggacf(df$y_t)
```


## Python code 

```{python}
#| label: python_pacf_plot

from statsmodels.tsa.stattools import acf
from statsmodels.stats.diagnostic import acorr_ljungbox
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

py_df = pd.read_csv('../../../raw_data/SBUX.csv')
py_df.index = py_df['date']
py_df = py_df.sort_index()

py_df_ts = pd.Series(py_df['adjClose'])
log_ret = np.log(1 + py_df_ts.pct_change())
log_ret = log_ret.dropna()

r, q, p = acf(log_ret, nlags = 25, qstat = True)

fig = plt.figure()
plot_acf(log_ret, lags=25)
plt.show()
```

```{python}

# q is for the Ljung-Box test statistics
q
```

```{python}

# p is for the p-value of the Ljung-Box statistics. 
p
```

```{python}
q1, p1 = acorr_ljungbox(log_ret, lags =25, return_df = False, boxpierce = False)
p1
```


```{python}
fig = plt.figure()
plot_pacf(log_ret, lags=25)
plt.show()
```

```{python}
log_ret.describe()

log_ret.plot()
plt.show()

pd.Series.idxmax(log_ret)
pd.Series.idxmin(log_ret)
```

# Time-series composition 

## Compose deterministic time-series (with trend and seasonality) with stochastic component 

```{r}
#| label: time_series_composition

df <- tibble(x = 1:252, phi = rnorm(252, mean = 0, sd = 1.5)) |> 
  mutate(y = 0.07 * x + 0.03 + phi)

ggplot(df, aes(x, y)) + 
  geom_line() + 
  ggtitle(label = 'Compose a linear trend with a stochastic component')

  
```

We can also create a seasonality with a stochastic component 

```{r}
df <- tibble(x = 1:252, phi = rnorm(252, mean = 0, sd = 1.5)) |> 
  mutate(y = 1.7 * sin((2 * pi * x / 50) + 0.3 * pi ) + phi)
         
ggplot(df, aes(x, y)) + 
  geom_line() + 
  ggtitle(label = 'Compose a seasonal trend with a stochastic component')
```



