{
  "hash": "cde55330878d86840b61a22662539afb",
  "result": {
    "markdown": "---\ntitle: \"03 - AutoCorrelation, Stationarity and Random-Walk - Part 1\"\nauthor: \"Francois de Ryckel\"\ndate: '2022-09-29'\ndescription: 'A dive into the concepts of autocorrelation and stationarity of time-series.  We also get into how to plot correlogram using R and Python, random-walk, white-noise.'\ncategories: [Time-Series, Autocorrelation, Stationarity, Random Walk]\ndate-modified: '2023-11-23'\n---\n\n\nThis post is to set up the basic concepts of time-series analysis.  \n\n# Autocovariance & autocorrelation \n\nAutocorrelation as the name indicates is the correlation of the time-series with itself, more specifically with a lag version of itself. We can think of it as many different coefficient of correlations.  One for each lag.  $r_2$ measure the correlation between the time series at time $t$ and time $t - 2$.  Similarly, $r_k$ measure the correlation between the time series at time $t$ and time $t - k$  \n\n$$r_k = \\frac{\\sum_{t=k+1}^T \\left( y_t - \\bar{y}\\right) \\left(y_{t-k} - \\bar{y} \\right)}{\\sum_{t=1}^T \\left(y_t - \\bar{y} \\right)^2}$$\n\nMore genrally, let's consider $\\{X_t\\}$ a time series.  \n\n*   Then the mean function of $\\{X_t\\}$ (the first moment) is defined as $\\mu_t = \\textbf{E}(X_t)$.  In other words, $\\mu_t$ is the expected value of the time series at point t.  \n*   The Variance of the time series is defined as $\\sigma_t ^2 = Var(X_t) = \\textbf{E}[(X_t - \\mu_t)^2]$. \n*   In general, $\\mu_t$ and $\\sigma_t ^2$ are different at different point in time. \n\nNow, we define the **autocovariance** function of the time series as \n$$\\gamma(s, t) = Cov(X_s, X_t) = \\textbf{E}[(X_s - \\mu_s)(X_t - \\mu_t)]$$  \nIn the same vein, we define the **autocorrelation** function of the time series as \n$$\\rho(s,t) = Corr(X_s, X_t) = \\frac {\\gamma (s, t)}{\\sigma_s \\sigma_t} = \\frac{Cov(X_s, X_t)}{\\sqrt{Var(X_s) Var(X_t)}}$$\n\nAutocovariance and autocorrelation measure the linear correlation between between two points $X_s$ and $X_t$ on the same time-series. \n\nFew properties of autocovariance and autocorrelation of time-series \n\n* $\\gamma(t, t) = \\sigma_t^2$ \n* $\\gamma(s, t) = \\gamma(t, s)$ \n* $|\\gamma(s, t)| \\le \\sigma_s \\sigma_t$ \n* $\\rho(t, t) \\equiv 1$\n\n## Autocorrelation plots - Correlogram \n\nAs exercise, we can plot the auto-correlation of a non-stationary (aka with significant autocorrelation) time-series.  We are using the [Monthly Milk production](https://www.kaggle.com/datasets/bhaveshsonagra/monthly-milk-production) (no idea where the data come from)\n\nOn the autocorrelation plot, the threshold line are situated at $\\pm \\frac{2}{\\sqrt{T}}$ . \n\nLet's maybe first have a visual of the data. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(tibble)\nlibrary(ggplot2)\n\nmilk <- read_csv('../../../raw_data/milk.csv')\n\nggplot(milk, aes(x = month, y = milk_prod_per_cow_kg)) + \n  geom_line()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/milk-production-1.png){width=672}\n:::\n:::\n\n\n\n\n### Using R \n\nIn R the standard function to plot a correlogram is the *acf()* function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacf(milk$milk_prod_per_cow_kg)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/acf-milk-1.png){width=672}\n:::\n:::\n\n\nGraph clearly shows some seasonality (at the 12 lags ==> yearly correlation) which indicates that our data are non-stationary (next section). The threshold line is at 0.154 as there are 168 observations in the dataset (number of monthly reported observations)\n\nIf we are more attached to the auto-correlation values, we can store the results in a dataframe. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nyo <- acf(milk$milk_prod_per_cow_kg, plot = F)\nyo\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAutocorrelations of series 'milk$milk_prod_per_cow_kg', by lag\n\n    0     1     2     3     4     5     6     7     8     9    10    11    12 \n1.000 0.892 0.778 0.620 0.487 0.428 0.376 0.415 0.454 0.562 0.687 0.769 0.845 \n   13    14    15    16    17    18    19    20    21    22 \n0.745 0.638 0.490 0.364 0.306 0.255 0.287 0.321 0.417 0.529 \n```\n:::\n:::\n\n\n\nWe could use the *ggplot* package to create a function to draw acf and get more customization.  We will re-use this function later as well. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# slightly fancier version (with more customization)\nggacf <- function(series, num_lags=25) {\n  significance_level <- qnorm((1 + 0.95)/2)/sqrt(sum(!is.na(series)))  \n  a <- acf(series, lag.max = num_lags, plot=F)\n  a.2 <- with(a, data.frame(lag, acf))\n  g <- ggplot(a.2[-1,], aes(x=lag,y=acf)) + \n    geom_segment(mapping = aes(xend = lag, yend = 0), linewidth = 0.8) + \n    xlab('Lag') + ylab('ACF') + \n    geom_hline(yintercept=c(significance_level,-significance_level), linetype= 'dashed', color = 'dodgerblue4');\n\n  # fix scale for integer lags\n  if (all(a.2$lag%%1 == 0)) {\n    g<- g + scale_x_discrete(limits = factor(seq(1, max(a.2$lag))));\n  }\n  return(g);\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggacf(milk$milk_prod_per_cow_kg, num_lags = 37)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/acf-milk-ggplot-1.png){width=672}\n:::\n:::\n\n\n### Using Python \n\nIn python, we need to use the *statsmodel* package. \n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom pandas import read_csv\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf\n\ndf = read_csv('../../../raw_data/milk.csv', index_col=0)\nplot_acf(df)\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n# Stationarity \n\nA time-series $\\{X_t\\}$ is (weakly) stationary if: \n\n* $E[X_t] = \\mu$ is a constant \n* $E[X_t^2] < \\infty$ \n* $Cov(X_t, X_{t+k}) = \\gamma(k)$ is independent of t for each integer k. $\\gamma(k)$ is called the lag $k$ autocovariance of function of $\\{X_t\\}$\n\n# PACF \n\nThe Partial Autocorrelation measures the correlation between $\\{X_{t-k} \\}$ and $\\{ X_t \\}$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npacf(milk$milk_prod_per_cow_kg)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-3.png){width=672}\n:::\n:::\n\n\n\n# Random Walk & White Noise \n\nWhite noise is a special type of time-series and a special case of stationarity. The concept emerge when studying **Random Walk**.  \n\n$\\{X_t\\}$ is a random-walk if it satisfies the equation: \n\n$$X_t = X_{t-1} + W_t$$ {#eq-rw1}\nwhere $\\{W_t\\}$ is a white-noise.  In other words, $W_t \\sim iid N(0, \\sigma_w^2)$\n\n\n\n$\\{W_t\\}$ is a white-noise if \n\n* $E[W_t] = \\mu$ is a constant for all t\n* $Var[W_t] = \\sigma_w^2$ is a constant \n* $Cov(W_s, W_t) = 0$ for any s and t with $s<t$.  In other words, any 2 subset of W are uncorrelated. \n\nIf $\\{W_t\\}$ is iid (independent and identically distributed) and $\\rho(k) = 1$ (when k=0) and $\\rho(k) = 0$ (otherwise, aka for any other values of k), then $\\{W_t\\}$ is a white noise. \n\nTherefore, as $n \\rightarrow \\infty$, we can say that $\\frac{1}{n} (X_1 + \\dots + X_n) = E[X_t] = \\mu$\n\n**A random walk is mean stationary**: $E(X_t) = E(X_0)$.  However, **the random walk is NOT variance stationary**: $Var(X_t) = Var(X_{t-1}) + \\sigma_w^2 \\gt Var(X_{t-1})$.  Also the **random-walk has no deterministic trend nor seasonality**. \n\nWe can generate white-noise in R using the arima.sim() function.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\n# Generate a white noise in R\nwn <- stats::arima.sim(model = list(order = c(0, 0, 0)), n = 250)\ndf <- tibble(x = 1:250, y = as.vector(wn))\n\nggplot(df, aes(x, y)) + \n  geom_line(color = 'dodgerblue3') + \n  xlab('Time') + ylab('White Noise') + \n  labs(title = 'Generated White Noise')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nAnd let's check the autocorrelation plot to visually confirm that. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# using the standard R function. \nacf(wn, lag.max = 20)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nWe could also use a ggplot function to plot the auto-correlation of our time-series. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggacf(wn)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## Statistical test to check white-noise. \n\nIn R we can use the Ljung-Box test (Portmanteau 'Q' test).  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nBox.test(wn, type = 'Ljung-Box', lag = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  wn\nX-squared = 4.8374, df = 1, p-value = 0.02785\n```\n:::\n:::\n\n\n# Application to a financial asset \n\nWe know that most financial assets prices are not stationary.  Let's take *SBUX* for instance. \nThat being said, the log difference of their prices is stationary.  Note how $log(P_t) - log(P{t-1}) = log( \\frac{P_t}{P_{t-1} )$\n\n## Using R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(lubridate)\n\ndf <- read_csv('../../../raw_data/SBUX.csv') |> arrange(date) |> \n  select(date, adjClose) |> \n  mutate(ret_1d = log(adjClose / lag(adjClose)), \n         ret_5d = log(adjClose / lag(adjClose, n = 5)), \n         y_t = log(adjClose) - log(lag(adjClose)), \n         day_of_week = weekdays(date)) |> \n  filter(date > '2018-01-01' & day_of_week == 'Tuesday')\n\nggacf(df$y_t)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n## Python code \n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.stats.diagnostic import acorr_ljungbox\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npy_df = pd.read_csv('../../../raw_data/SBUX.csv')\npy_df.index = py_df['date']\npy_df = py_df.sort_index()\n\npy_df_ts = pd.Series(py_df['adjClose'])\nlog_ret = np.log(1 + py_df_ts.pct_change())\nlog_ret = log_ret.dropna()\n\nr, q, p = acf(log_ret, nlags = 25, qstat = True)\n\nfig = plt.figure()\nplot_acf(log_ret, lags=25)\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/python_pacf_plot-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/python_pacf_plot-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# q is for the Ljung-Box test statistics\nq\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([26.3136516 , 26.316042  , 26.4475469 , 27.2734633 , 28.00235211,\n       28.69472715, 28.70545674, 35.25084316, 39.48634821, 39.62923899,\n       40.19059746, 40.26948906, 40.2707996 , 40.27868851, 44.51737182,\n       44.57802557, 45.63422739, 45.70863764, 46.1791967 , 46.4744188 ,\n       47.53325326, 48.52664511, 49.81175008, 50.99884363, 54.25246436])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# p is for the p-value of the Ljung-Box statistics. \np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([2.90229916e-07, 1.92994124e-06, 7.68595886e-06, 1.75019647e-05,\n       3.63602517e-05, 6.94858936e-05, 1.63715557e-04, 2.40667022e-05,\n       9.41189824e-06, 1.96904817e-05, 3.31867363e-05, 6.48649190e-05,\n       1.25022094e-04, 2.30799458e-04, 9.12196699e-05, 1.61044765e-04,\n       1.95803242e-04, 3.27130628e-04, 4.67495545e-04, 6.93532977e-04,\n       7.95682642e-04, 9.24023511e-04, 9.75159499e-04, 1.05482880e-03,\n       6.16160760e-04])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nq1, p1 = acorr_ljungbox(log_ret, lags =25, return_df = False, boxpierce = False)\np1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'lb_pvalue'\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfig = plt.figure()\nplot_pacf(log_ret, lags=25)\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-5.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-6.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlog_ret.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncount    5653.000000\nmean        0.000559\nstd         0.019890\nmin        -0.176788\n25%        -0.008773\n50%         0.000345\n75%         0.009802\nmax         0.168728\nName: adjClose, dtype: float64\n```\n:::\n\n```{.python .cell-code}\nlog_ret.plot()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-9.png){width=672}\n:::\n\n```{.python .cell-code}\npd.Series.idxmax(log_ret)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'2009-07-22'\n```\n:::\n\n```{.python .cell-code}\npd.Series.idxmin(log_ret)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'2020-03-16'\n```\n:::\n:::\n\n\n\n# Python Code \n\n## A random-walk \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom numpy.random import normal\n\nnp.random.seed(190224)\na = normal(size = 500); b = normal(size = 500); c = normal(size = 500)\nx = np.cumsum(a); y = np.cumsum(b); z = np.cumsum(c)\n\ndf = pd.DataFrame({'x':x, 'y':y, 'z':z})\ndf.index = range(1, 501)\ndf.plot(style = ['-', '--', ':'])\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-11.png){width=672}\n:::\n:::\n\n\n## Making a non-stationary time-series stationary \n\nAs shown above one way to make a time-series stationary is to take its first difference (or logarithm of its first difference)\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('../../../raw_data/JPM.csv')\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df[df['Date'] > '2019-01-01']\ndf.index = df['Date']\nprice = df['Adj Close']\n\n\nplt.clf()\nprice.plot()\nplt.title('Price of JPM')\nplt.ylabel('Price (in USD)')\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-13.png){width=672}\n:::\n\n```{.python .cell-code}\n# And checking the acf and pcaf\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf\n\nplt.clf()\nplot_acf(price)\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-14.png){width=672}\n:::\n\n```{.python .cell-code}\nplt.clf()\nlog_price = np.log(price)\nlog_price.plot()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-15.png){width=672}\n:::\n\n```{.python .cell-code}\nplt.clf()\ndiff_log_price = log_price.diff(1)\ndiff_log_price.plot()\nplt.title('Difference of log price of JPM')\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-16.png){width=672}\n:::\n\n```{.python .cell-code}\nplot_acf(diff_log_price.iloc[1:,])\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-17.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}