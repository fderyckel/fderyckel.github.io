{
  "hash": "0f7f783d7ce3d9ab9b6303751a2c297f",
  "result": {
    "markdown": "---\ntitle: \"Translating Python Part 1 - Xgboost with Time-Series\"\nauthor: \"Francois de Ryckel\"\ndate: \"2022-10-01\"\ncategories: [xgboost, code, analysis, tidymodel]\neditor: source\n---\n\n\nThis post is about using xgboost on a time-series using both R with the tidymodel framework and python.  It is part of a series of articles aiming at translating python timeseries blog articles into their tidymodels equivalent. \n\nThe raw data is quite simple as it is energy consumption based on an hourly consumption. Original article can be found [here](https://www.kaggle.com/code/robikscube/tutorial-time-series-forecasting-with-xgboost/notebook).  Minimal changes were made to better fit current python practices.  \n\nXgboost is part of the ensemble machine learning algorithms.  It can be used for both regression and classification.  There are few issues in using Xgboost with time-series.  This article is taking a Xgboost post in python and also translating with the new R tidymodel framework.  \n\n# Loading data and features engineering \n\n## Using R \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# setting up main R libraries to start \nthe_path <- here::here()\nlibrary(glue)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\ndf0 <- read_csv(glue(the_path, \"/raw_data/AEP_hourly.csv\"))\n# let's have a quick look at what we are dealing with\nglimpse(df0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 121,273\nColumns: 2\n$ Datetime <dttm> 2004-12-31 01:00:00, 2004-12-31 02:00:00, 2004-12-31 03:00:0…\n$ AEP_MW   <dbl> 13478, 12865, 12577, 12517, 12670, 13038, 13692, 14297, 14719…\n```\n:::\n:::\n\n\nThere are only 2 variables.  The Datetime being the only independ variable.  And the energy consumption labelled as AEP_MW being our variable to predict. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# and graphically - \n# just using a couple of years to get an idea \nggplot(df0 |> filter(Datetime > \"2014-01-01\" & Datetime < \"2016-01-01\"), aes(x =Datetime, y=AEP_MW )) + geom_line(color = \"light blue\")\n```\n\n::: {.cell-output-display}\n![Graphical glimpse of our raw data](index_files/figure-html/fig-r-dataglimpse-1.png){#fig-r-dataglimpse width=672}\n:::\n:::\n\n\nAs Datetime is our only input variable, we'll use the usual tricks of breaking it down into week number, months, etc. I am doing it slightly differently than in the python version here as I will first create the new time related variables then I will split it into training and testing. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\ndf <- df0 |> \n  mutate(hour = hour(Datetime), \n         day_of_week = wday(Datetime), \n         day_of_year = yday(Datetime), \n         day_of_month = mday(Datetime), \n         week_of_year = isoweek(Datetime), \n         month = month(Datetime), \n         quarter = quarter(Datetime), \n         year = isoyear(Datetime)\n         ) \n# another glimpse now. \nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 121,273\nColumns: 10\n$ Datetime     <dttm> 2004-12-31 01:00:00, 2004-12-31 02:00:00, 2004-12-31 03:…\n$ AEP_MW       <dbl> 13478, 12865, 12577, 12517, 12670, 13038, 13692, 14297, 1…\n$ hour         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ day_of_week  <dbl> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, …\n$ day_of_year  <dbl> 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 36…\n$ day_of_month <int> 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 3…\n$ week_of_year <dbl> 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 5…\n$ month        <dbl> 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1…\n$ quarter      <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, …\n$ year         <dbl> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 200…\n```\n:::\n:::\n\n\nAlthough, there are only 2 variables, there are over 120,000 rows of data.  That's non-negligible. \n\n## Using python \n\nThis is the code from the original post. \n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\npy_df = pd.read_csv(\"../../raw_data/AEP_hourly.csv\", index_col = [0], parse_dates = [0])\npy_df.tail()\n#plt.plot(df0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      AEP_MW\nDatetime                    \n2018-01-01 20:00:00  21089.0\n2018-01-01 21:00:00  20999.0\n2018-01-01 22:00:00  20820.0\n2018-01-01 23:00:00  20415.0\n2018-01-02 00:00:00  19993.0\n```\n:::\n\n```{.python .cell-code}\nsplit_date = '01-jan-2016'\npy_df_train = py_df.loc[py_df.index <= split_date].copy()\npy_df_test = py_df.loc[py_df.index > split_date].copy()\n```\n:::\n\n\nThe author of the python blog first created a train / test set then created a function to add the variables then applied that function to both sets.  This is a very valid way of doing things when steps include normalizing and/or scaling data before applying our ML algorithms as we don't want any leakage from our training set into our testing set. \n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Create features of df\ndef create_features(df, label = None): \n  df['date'] = df.index \n  df['hour'] = df['date'].dt.hour\n  df['day_of_week'] = df['date'].dt.dayofweek\n  df['day_of_year'] = df['date'].dt.dayofyear \n  df['day_of_month'] = df['date'].dt.day \n  df['week_of_year'] = df['date'].dt.isocalendar().week \n  df['month'] = df['date'].dt.month \n  df['quarter'] = df['date'].dt.quarter \n  df['year'] = df['date'].dt.year\n  \n  X = df[['hour', 'day_of_week', 'day_of_year', 'day_of_month', 'week_of_year', 'month', 'quarter', 'year']]\n  \n  if label: \n    y = df[label]\n    return X, y\n  \n  return X\n```\n:::\n\n\nCompare this way of constructing variables to the much easier and more elegant tidyverse's way of cleaning and creating variables. \nThe **dplyr** [package](https://dplyr.tidyverse.org/) really makes it painless to wrangle data.  \n\n# Spliting the data into a training and testing set \n\n## Using R \n\n*Rsample* is the [tidymodel package](https://rsample.tidymodels.org/) that deals with creating training and testing sets.  There are really many methods available to do this, but we stick to the same methods provided in the original blog post. There are out-of-the-box methods to deal with timeseries like in this case. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rsample)\nprop_split = 1 - (nrow(df |> filter(Datetime > \"2016-01-01\")) / nrow(df))\ndf_split <- initial_time_split(df |> arrange(Datetime), prop = prop_split)\ndf_train <- training(df_split)\ndf_test <- testing(df_split)\n```\n:::\n\n\n## Using Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\npy_x_train, py_y_train = create_features(py_df_train, label = \"AEP_MW\")\npy_x_test, py_y_test =   create_features(py_df_test, label = \"AEP_MW\")\n#When running xgboost, I got an issue with one of the type of the variable.  \n# Let's fix this. \npy_x_train.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 98594 entries, 2004-12-31 01:00:00 to 2015-01-02 00:00:00\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   hour          98594 non-null  int64 \n 1   day_of_week   98594 non-null  int64 \n 2   day_of_year   98594 non-null  int64 \n 3   day_of_month  98594 non-null  int64 \n 4   week_of_year  98594 non-null  UInt32\n 5   month         98594 non-null  int64 \n 6   quarter       98594 non-null  int64 \n 7   year          98594 non-null  int64 \ndtypes: UInt32(1), int64(7)\nmemory usage: 6.5 MB\n```\n:::\n\n```{.python .cell-code}\npy_x_train = py_x_train.astype(np.int64)\npy_x_test = py_x_test.astype(np.int64)\npy_x_train.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 98594 entries, 2004-12-31 01:00:00 to 2015-01-02 00:00:00\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype\n---  ------        --------------  -----\n 0   hour          98594 non-null  int64\n 1   day_of_week   98594 non-null  int64\n 2   day_of_year   98594 non-null  int64\n 3   day_of_month  98594 non-null  int64\n 4   week_of_year  98594 non-null  int64\n 5   month         98594 non-null  int64\n 6   quarter       98594 non-null  int64\n 7   year          98594 non-null  int64\ndtypes: int64(8)\nmemory usage: 6.8 MB\n```\n:::\n:::\n\n\n# Modeling \n\n## Using R \n\nAgain this is a very straightforward xgboost application to a dataset.  No fine tuning of models, recipe, etc.  \n\n\n::: {.cell hash='index_cache/html/the-r-model_8017c4063f88538067e748fbf2b2b9b4'}\n\n```{.r .cell-code}\nlibrary(parsnip)\nmodel_xgboost <- boost_tree(stop_iter = 50L, trees=1000L) |> \n  set_engine(\"xgboost\") |>\n  set_mode(\"regression\")\n  \nfit_xgboost <- model_xgboost |> \n  fit(AEP_MW ~., data = df_train %>% select(-Datetime))\nfit_xgboost\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nparsnip model object\n\n##### xgb.Booster\nraw: 4.7 Mb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1, \n    subsample = 1), data = x$data, nrounds = 1000L, watchlist = x$watchlist, \n    verbose = 0, early_stopping_rounds = 50L, nthread = 1, objective = \"reg:squarederror\")\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", nthread = \"1\", objective = \"reg:squarederror\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  best_iteration, best_msg, best_ntreelimit, best_score, niter\ncallbacks:\n  cb.evaluation.log()\n  cb.early.stop(stopping_rounds = early_stopping_rounds, maximize = maximize, \n    verbose = verbose)\n# of features: 8 \nniter: 1000\nbest_iteration : 1000 \nbest_ntreelimit : 1000 \nbest_score : 242.3155 \nbest_msg : [1000]\ttraining-rmse:242.315489 \nnfeatures : 8 \nevaluation_log:\n    iter training_rmse\n       1    11175.8839\n       2     7906.5875\n---                   \n     999      242.5272\n    1000      242.3155\n```\n:::\n:::\n\n\n## Using Python \n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom xgboost.sklearn import XGBRegressor\npy_xgboost_mod = XGBRegressor(n_estimator = 1000, early_stopping_rounds = 50)\npy_xgboost_mod.fit(py_x_train, py_y_train, \n                   eval_set = [(py_x_train, py_y_train), (py_x_test, py_y_test)], \n                   verbose = True)\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=50, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n             importance_type=None, interaction_constraints=&#x27;&#x27;,\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimator=1000,\n             n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n             random_state=0, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=50, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n             importance_type=None, interaction_constraints=&#x27;&#x27;,\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimator=1000,\n             n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n             random_state=0, reg_alpha=0, ...)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n\n# Features importance \n\n## Using R \n\n2 ways to do this ... (actually more than 2 ways, but here are 2 main ways.).  First one is a straight table using the xgboost library itself. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(xgboost)\nxgb.importance(model = fit_xgboost$fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        Feature        Gain       Cover    Frequency\n1:  day_of_year 0.361828048 0.455387001 0.2800303942\n2:         hour 0.336852823 0.125331328 0.2374139102\n3:         year 0.120129969 0.129691117 0.2000679018\n4:  day_of_week 0.105250594 0.073258066 0.1489636887\n5: week_of_year 0.047083085 0.097216236 0.0462379151\n6: day_of_month 0.027801118 0.116483820 0.0864293336\n7:        month 0.001054362 0.002632432 0.0008568565\n```\n:::\n\n```{.r .cell-code}\n#detach(xgboost)\n```\n:::\n\n\nAnd also a graphic way. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\nfit_xgboost %>%\n  vip(geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## Using python \n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom xgboost import plot_importance, plot_tree\n_ = plot_importance(py_xgboost_mod, height=0.9)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nI am a bit confused here in the output of the python graph with F-score vs the output of the R graph with importance. \n\n# Checking predictions and evaluating models \n\n## Using R \n\nGraphing predicted power output vs actual power output could be a first way to see how our model fares in its predictions. \nSo let's graph our datetime vs power ouput for both actual and predicted. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tibble)  # for the add_column \nlibrary(parsnip)\ndf_test1 <- add_column(df_test,  predict(fit_xgboost, new_data = df_test)) \nggplot(df_test1, aes(x= Datetime, y = AEP_MW)) + \n  geom_line(color = \"blue\") + \n  geom_line(aes(y = .pred), color = \"yellow\", alpha = 0.5) + \n  labs(title = \"Energy Consumption in 2016-2018 (in MWh)\", y = \"Hourly consumption\")\n```\n\n::: {.cell-output-display}\n![Actual Vs Predicted power consumption for 2016-2018](index_files/figure-html/fig-r-actual_vs_predict_overall-3.png){#fig-r-actual_vs_predict_overall width=864}\n:::\n:::\n\nWe can already see that we are not really modeling well the peaks and through.  \nWe could get slightly more granular and try to see whats going on. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df_test1 %>% filter(Datetime > \"2016-01-01\" & Datetime < \"2016-02-28\"), aes(x= Datetime, y = AEP_MW)) + \n  geom_line(color = \"blue\") + \n  geom_line(aes(y = .pred), color = \"yellow3\", alpha = 0.8)\n```\n\n::: {.cell-output-display}\n![Actual Vs Predicted power consumption](index_files/figure-html/fig-r-actual_vs_predict_granular-1.png){#fig-r-actual_vs_predict_granular width=960}\n:::\n:::\n\n\nWe are clearly off there on the second half of February.  \n\nNow, we can use the yardstick package to get numerical values to assess our model on the test set.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(yardstick)\n# calculating the RMSE (root mean square error)\nrmse(df_test1, truth = AEP_MW, estimate = .pred, na_rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       2067.\n```\n:::\n\n```{.r .cell-code}\n# calculating the MAE (mean absolute error)\nmae(df_test1, truth = AEP_MW, estimate = .pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 mae     standard       1495.\n```\n:::\n\n```{.r .cell-code}\n# calculating the MAPE (mean absolute percent error)\nmape(df_test1, truth = AEP_MW, estimate = .pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 mape    standard        10.0\n```\n:::\n\n```{.r .cell-code}\n# actually much easier to use the metric_set() function !\nxgboost_mod_metrics <- metric_set(rmse, mae, mape)\nxgboost_mod_metrics(df_test1, truth = AEP_MW, estimate = .pred) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      2067. \n2 mae     standard      1495. \n3 mape    standard        10.0\n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}