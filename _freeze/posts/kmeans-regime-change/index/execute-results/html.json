{
  "hash": "48c6393def539f0b0f7a1225afd0f9ca",
  "result": {
    "markdown": "---\ntitle: \"Kmeans with regime changes\"\nauthor: \"Francois de Ryckel\"\ndate: '2022-10-12'\ncategories: [kmeans, code, analysis, tidymodel]\neditor: source\ndate-modified: '2022-10-12'\n---\n\n\nThis post is about how to use Kmeans to classify various market regimes or to use Kmeans to classify financial observations. \n\n::: {.callout-tip appearance=\"simple\"} \n\n# Market regime \n\nFinancial markets have the tendency to change their behavior over time, which can create regimes, or periods of fairly persistent market conditions. Investors often look to discern the current market regime, looking out for any changes to it and how those might affect the individual components of their portfolio’s asset allocation. Modeling various market regimes can be an effective tool, as it can enable macro-economically aware investment decision-making and better management of tail risks. \n\n:::\n\nWith K-means we are trying to establish groups of data that are **homegenous** and **distinctly different** from other groups.  The *K-* stands for the number of clusters we will create.  \n\nThe concept of distance comes in when deciding if a data point belongs to a cluster. The most common way to measure distance is the **Euclidean Distance**.  \n\nWith multivariate data set, it is important to normalize the data.  \nA usual rule of thumb is to set the number of clusters as the square root of the number of observation. \n\n# Using R \n\n## Load up packages and read data \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)        # load and read .csv file\nlibrary(glue)         # concatenate strings together\nlibrary(dplyr)        # the tidy plyr tool for data wrangling\nlibrary(tidyr)        # to use the drop_na function\nthe_path <- here::here()\ndf <- read_csv(glue(the_path, \"/raw_data/AMD.csv\")) |> \n  rename(adj_close = 'adjClose') |> \n  select(date, high, low, close, adj_close)\nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 5,611\nColumns: 5\n$ date      <date> 2023-04-21, 2023-04-20, 2023-04-19, 2023-04-18, 2023-04-17,…\n$ high      <dbl> 89.8000, 91.5795, 90.5400, 92.1600, 90.6900, 92.9700, 93.160…\n$ low       <dbl> 88.0550, 88.7300, 88.2200, 89.3300, 88.3000, 90.5000, 91.830…\n$ close     <dbl> 88.43, 90.11, 89.94, 89.78, 89.87, 91.75, 92.09, 92.33, 94.0…\n$ adj_close <dbl> 88.43, 90.11, 89.94, 89.78, 89.87, 91.75, 92.09, 92.33, 94.0…\n```\n:::\n:::\n\n\n## Feature engineering \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(TTR)      # The technical analysis package\nyo <- aroon(df[, c('high', 'low')], n = 23)\ndf$aroon <- yo[, 3]\nyo <- CCI(df[, c('high', 'low', 'close')], n = 17)\ndf$cci <- yo\nyo <- chaikinVolatility(df[, c('high', 'low')], n = 13)\ndf$chaikinVol <- yo\ndf1 <- df |> \n  select(date, aroon, cci, chaikinVol, adj_close) |> \n  mutate(across(c(aroon, cci, chaikinVol), ~ as.numeric(scale(.)))) |>\n  drop_na()\nskimr::skim(df1 %>% select(-date))\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |                      |\n|:------------------------|:---------------------|\n|Name                     |df1 %>% select(-date) |\n|Number of rows           |5586                  |\n|Number of columns        |4                     |\n|_______________________  |                      |\n|Column type frequency:   |                      |\n|numeric                  |4                     |\n|________________________ |                      |\n|Group variables          |None                  |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|    sd|    p0|   p25|   p50|   p75|   p100|hist  |\n|:-------------|---------:|-------------:|-----:|-----:|-----:|-----:|-----:|-----:|------:|:-----|\n|aroon         |         0|             1|  0.00|  1.00| -1.49| -0.94| -0.19|  0.90|   1.65|▇▆▂▆▆ |\n|cci           |         0|             1|  0.00|  1.00| -4.66| -0.78| -0.08|  0.80|   4.06|▁▂▇▅▁ |\n|chaikinVol    |         0|             1|  0.00|  1.00| -2.49| -0.70| -0.10|  0.59|   4.37|▂▇▅▁▁ |\n|adj_close     |         0|             1| 22.27| 28.78|  1.62|  5.45| 11.48| 23.12| 161.91|▇▁▁▁▁ |\n:::\n\n```{.r .cell-code}\n# also good to check for correlation between variables. \nlibrary(corrr)\ndf1 |> select(-date, -adj_close) |> \n  correlate() |> \n  rearrange() |> \n  shave()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  term          cci  aroon chaikinVol\n  <chr>       <dbl>  <dbl>      <dbl>\n1 cci        NA     NA             NA\n2 aroon       0.564 NA             NA\n3 chaikinVol  0.212  0.223         NA\n```\n:::\n:::\n\n\nThese 3 variables seem to complete each other well as little to-no correlation. \n\n## Create clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)     #use the map function\nlibrary(broom)     #use the glance function on kmeans \ndf1sc <- df1 %>% select(-date, -adj_close)\nkclusts <- tibble(k = 1:9) |> \n  mutate(kclust = map(k, ~kmeans(df1sc, centers = .x, nstart = 30, iter.max = 50L)), \n         glanced = map(kclust, glance), \n         augmented = map(kclust, augment, df1))\nkclusts |> unnest(cols = c('glanced'))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 7\n      k kclust    totss tot.withinss betweenss  iter augmented           \n  <int> <list>    <dbl>        <dbl>     <dbl> <int> <list>              \n1     1 <kmeans> 16755.       16755. -2.04e-10     1 <tibble [5,586 × 6]>\n2     2 <kmeans> 16755.        9842.  6.91e+ 3     1 <tibble [5,586 × 6]>\n3     3 <kmeans> 16755.        7916.  8.84e+ 3     3 <tibble [5,586 × 6]>\n4     4 <kmeans> 16755.        6425.  1.03e+ 4     4 <tibble [5,586 × 6]>\n5     5 <kmeans> 16755.        5492.  1.13e+ 4     4 <tibble [5,586 × 6]>\n6     6 <kmeans> 16755.        4626.  1.21e+ 4     6 <tibble [5,586 × 6]>\n7     7 <kmeans> 16755.        4199.  1.26e+ 4     4 <tibble [5,586 × 6]>\n8     8 <kmeans> 16755.        3791.  1.30e+ 4     7 <tibble [5,586 × 6]>\n9     9 <kmeans> 16755.        3477.  1.33e+ 4     4 <tibble [5,586 × 6]>\n```\n:::\n:::\n\n\nThere are several ways to choose the ideal number of clusters.  One of them is the elbow method, another one is the Silhouette Method. \n\nThe **tot.withinss** is the total within-cluster sum of square. This is the value used for the eblow method. \n\nFor the Silhouette Method, we can use the **cluster** package. \n\n\n::: {.cell hash='index_cache/html/calculate_silhoutte_value_in_r_29551b6d1f724e162cf46789790c52b6'}\n\n```{.r .cell-code}\navg_sil <- function(k) { \n  kmeans_object <- kmeans(df1sc, centers = k, iter.max = 50L)\n  silh = cluster::silhouette(kmeans_object$cluster, dist(df1sc))\n  mean(silh[, 3])\n  }\n# Compute and plot wss for k = 2 to k = 15\nyo <- tibble(k_values =  2:9) |> \n  mutate(avg_sil_values = map_dbl(k_values, avg_sil))\nyo\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 2\n  k_values avg_sil_values\n     <int>          <dbl>\n1        2          0.378\n2        3          0.345\n3        4          0.286\n4        5          0.312\n5        6          0.296\n6        7          0.284\n7        8          0.295\n8        9          0.279\n```\n:::\n:::\n\n\nA more elegant way to do that, using [this post from SO](https://stackoverflow.com/questions/63780363/r-using-purrr-map-function-to-calculate-silhouette-distances-of-kmeans-model)\n\n::: {.cell hash='index_cache/html/calculate_silhoutte_value_in_r_elegant_b52dd31c30b867503fdfd81d0917ee01'}\n\n```{.r .cell-code}\nyo <- kclusts |> \n  mutate(silhouetted = map(augmented, ~ cluster::silhouette(as.numeric(levels(.x$.cluster))[.x$.cluster], dist(df1sc)))) |> \n  select(k, silhouetted) |> unnest(cols=c('silhouetted')) |> \n  group_by(k) %>% \n  summarise(avg_sil_values = mean(silhouetted[,3]))\nyo\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 2\n      k avg_sil_values\n  <int>          <dbl>\n1     1         NA    \n2     2          0.378\n3     3          0.345\n4     4          0.293\n5     5          0.313\n6     6          0.320\n7     7          0.305\n8     8          0.298\n9     9          0.273\n```\n:::\n:::\n\n\n\n\n## Some visualizations \n\n### Elbow method \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nkclusts |> \n  unnest(cols = c('glanced')) |> \n  ggplot(aes(k, tot.withinss)) + \n  geom_line(alpha = 0.5, size = 1.2, color = 'midnightblue') + \n  geom_point(size = 2, color = 'midnightblue')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![Total within-cluster sum of square for k-cluster](index_files/figure-html/vizualise_kmeans_elbow-1.png){width=672}\n:::\n:::\n\nBased on the elbow method, I would be tempted to choose to 5 clusters (2 seems another obvious one).  \n\n### Silhouette Method \n\n\n::: {.cell}\n\n```{.r .cell-code}\nyo |> ggplot(aes(k, avg_sil_values)) + \n  geom_line(alpha = 0.5, size = 1.2, color = 'midnightblue') + \n  geom_point(size = 2, color = 'midnightblue')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 row containing missing values (`geom_line()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![Silhouette score for k-clusters](index_files/figure-html/silhouette_score_graph_r-1.png){width=672}\n:::\n:::\n\n2 is the winner ;-) \n\n### Plotting the stocks with clustered observations \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nyo <- kmeans(df1 |> select(-date, -adj_close), centers = 2)\naugment(yo, df1) |> filter(date >= today() - 500) |> \n  ggplot(aes(x = date, y = adj_close)) + \n    geom_line(alpha = 0.5, color = 'midnightblue') + \n    geom_point(aes(color = .cluster)) + \n    theme(legend.position = 'none')\n```\n\n::: {.cell-output-display}\n![Plotting adjusted close price with only 2 clusters](index_files/figure-html/plotting_with_2clusters_observation-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nyo <- kmeans(df1 |> select(-date, -adj_close), centers = 3)\naugment(yo, df1) |> filter(date >= today() - 500) |> \n  ggplot(aes(x = date, y = adj_close)) + \n    geom_line(alpha = 0.5, color = 'midnightblue') + \n    geom_point(aes(color = .cluster)) + \n    theme(legend.position = 'none')\n```\n\n::: {.cell-output-display}\n![Plotting adjusted close price with only 3 clusters](index_files/figure-html/plotting_with_only_3clusters-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nyo <- kmeans(df1 |> select(-date, -adj_close), centers = 6)\naugment(yo, df1) |> filter(date >= today() - 500) |> \n  ggplot(aes(x = date, y = adj_close)) + \n    geom_line(alpha = 0.5, color = 'midnightblue') + \n    geom_point(aes(color = .cluster)) + \n    theme(legend.position = 'none')\n```\n\n::: {.cell-output-display}\n![Plotting adjusted close price with only 6 clusters](index_files/figure-html/platting_with_only_6clusters-1.png){width=672}\n:::\n:::\n\n\n\n# Using python \nOriginal blog post \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport yfinance as yf     #only to download data\ndata  = yf.download(\"AMD\")\ndata.to_csv(\"../../raw_data/AMD.csv\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\npy_df = pd.read_csv(\"../../raw_data/intc.csv\", names = ['date', 'open', 'high', 'low', 'close', 'adj_close', 'volume']).iloc[1: , :]\npy_df.tail()\npy_df.info()\npy_df.shape\npy_df_melt = py_df.melt(id_vars = 'date', value_vars = ['open', 'high', 'low', 'close'], value_name = 'prices', var_name = 'price_point')\npy_df_melt.info()\npy_df_melt.shape\n```\n:::\n\n\n\nLet's graph the last year of data \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport matplotlib.pyplot as plt\nta_df2 = ta_df.tail(250).copy()\nta_df2['adj_close'] = py_df['adj_close']\nta_df2['date_time'] = pd.to_datetime(ta_df2['date_time'], utc=True)\nta_df2['adj_close'] = pd.to_numeric(ta_df2['adj_close'])\nfig = plt.figure(figsize = (12, 8)) \ngs = fig.add_gridspec(3, hspace=0)\naxs = gs.subplots(sharex=True)\n#plt.figure(figsize = (12, 8))\naxs[0].plot(ta_df2['date_time'], ta_df2['adj_close'])\naxs[0].set_ylim(25, 55)\n#axs[0].set_title('INTC price')\naxs[1].plot(ta_df2['date_time'], ta_df2['aaron'],  'tab:green')\naxs[1].set_ylim(-105, 105)\n#axs[1].set_title('Aaron ind.')\naxs[2].plot(ta_df2['date_time'], ta_df2['ht'], 'tab:red')\naxs[2].set_ylim(-50,320)\nfor ax in axs:\n    ax.label_outer()\n    \nplt.show()\n```\n:::\n\n::: {.cell hash='index_cache/html/model_cluster_in_python_601ab53bbf608b02bda1444a90ca3847'}\n\n```{.python .cell-code}\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans\ninertia = []\nsil_score = []\nta_df.pop('date_time')\nfor n_clusters in range(2, 14): \n  kmeans = KMeans(n_clusters = n_clusters, random_state=0)\n  preds = kmeans.fit_predict(ta_df)\n  inertia.append(kmeans.inertia_ / n_clusters)\n  sil_score.append(silhouette_score(ta_df, preds))\n  \ninertias = pd.DataFrame({n_clusters: range(2, 14), \"inertia\": inertia})\nsil_scores = pd.DataFrame({n_clusters: range(2, 14), \"sil_score\": sil_score})\nprint(inertias)\nprint(sil_scores)\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}